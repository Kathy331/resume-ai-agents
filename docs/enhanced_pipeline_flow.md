# Enhanced Email Pipeline Flow with LangGraph

## Flow Diagram

```
ðŸ“§ Raw Emails
    â†“
ðŸ·ï¸  Email Classification
    â†“
    â”œâ”€ Interview_invite? â”€â”€â†’ YES â”€â”€â†’ ðŸ§  Entity Extraction
    â”‚                                    â†“
    â”‚                               ðŸ“‹ Memory Similarity Check
    â”‚                                    â†“
    â”‚                               â”Œâ”€ High Similarity + Prepped? â”€â”€â†’ YES â”€â”€â†’ â­ï¸  Skip Research
    â”‚                               â”‚                                          â†“
    â”‚                               â””â”€ NO â”€â”€â†’ ðŸ” Tavily Research â”€â”€â†’ ðŸ’¾ Update Memory
    â”‚                                                â†“
    â””â”€ Other Categories â”€â”€â†’ ðŸ“Š Format Output â†â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                          âœ… Complete
```

## LangGraph Nodes

1. **setup_gmail** - Initialize Gmail service
2. **fetch_emails** - Retrieve emails from specified folder
3. **classify_emails** - Categorize emails (Interview_invite, Personal, etc.)
4. **setup_enhanced_pipeline** - Initialize enhanced processing agents
5. **process_interviews** - Advanced interview processing chain:
   - Entity extraction (Company, Role, Date, Interviewer)
   - Memory similarity search
   - Conditional research based on similarity scores
   - Memory storage/updates
6. **format_output** - Generate user-friendly summaries
7. **error_handler** - Handle errors with retry logic

## Conditional Routing Logic

### Route: `route_after_classification`
- If Interview_invite emails detected â†’ `setup_enhanced_pipeline`
- If no interviews â†’ `format_output`
- If error â†’ `error_handler`

### Route: `process_interviews` Decision Tree
```python
For each Interview_invite email:
    1. Extract entities (Company, Role, Candidate, Date, etc.)
    2. Query memory for similar interviews
    3. Calculate similarity scores
    4. Decision:
        - If similarity > 0.8 AND status in ['prepped', 'scheduled', 'completed']:
            â†’ Skip research, log as "found in memory"
        - Else:
            â†’ Perform Tavily research
            â†’ Store/update in memory with status='preparing'
```

## State Management

The `EmailWorkflowState` carries data through each node:

```python
{
    'folder_name': str,
    'gmail_service': GmailService,
    'raw_emails': List[Dict],
    'classified_emails': Dict[str, List],
    'interview_processing_results': List[Dict],  # Enhanced results
    'enhanced_pipeline': EnhancedEmailPipeline,
    'research_performed_count': int,
    'memory_hits_count': int,
    'summaries': List[Dict],
    'processing_complete': bool
}
```

## Benefits

1. **Intelligent Deduplication** - Avoids redundant research for similar interviews
2. **Memory-Driven Efficiency** - Leverages past processing to speed up new emails
3. **Conditional Processing** - Only performs expensive operations when needed
4. **State Persistence** - Tracks interview lifecycle (preparing â†’ prepped â†’ completed)
5. **Scalable Architecture** - Easy to add new processing nodes or routing logic

## Usage

```python
# Run the enhanced pipeline
from agents.orchestrator.workflow_runner import WorkflowRunner

runner = WorkflowRunner()
result = runner.run_email_pipeline(folder_name='INBOX', max_results=10)

# Results include enhanced metrics
print(f"Research performed: {result['research_performed_count']}")
print(f"Memory hits: {result['memory_hits_count']}")
```
